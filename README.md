# Identificaci√≥n de personas por caminata usando landmarks corporales üö∂‚Äç‚ôÄÔ∏è

Este proyecto forma parte de la Maestr√≠a en Ciencias de la Computaci√≥n y
consiste en desarrollar un sistema para la identificaci√≥n de personas a
partir de secuencias de caminata, utilizando landmarks corporales obtenidos
de videos.

Se trabaj√≥ con un conjunto de datos colectivo de secuencias grabadas por
diferentes personas, utilizando un conjunto para entrenamiento y un
conjunto independiente para validaci√≥n externa.

## üß† Descripci√≥n

El objetivo principal es transformar secuencias de pose corporal en
descriptores num√©ricos y entrenar modelos de clasificaci√≥n para identificar
a qu√© persona pertenece cada secuencia de caminata.

Durante el desarrollo se realizaron los siguientes pasos principales:

- Extracci√≥n de landmarks corporales por frame utilizando MediaPipe Pose.
- Construcci√≥n de archivos CSV con las coordenadas 3D de cada articulaci√≥n.
- Extracci√≥n de caracter√≠sticas estad√≠sticas por secuencia.
- Escalado de las caracter√≠sticas.
- Entrenamiento de distintos modelos de clasificaci√≥n.
- Evaluaci√≥n mediante validaci√≥n cruzada y an√°lisis cualitativo de errores.

## üõ†Ô∏è Modelos utilizados

Se evaluaron distintos modelos, seleccionados por su simplicidad y buen
desempe√±o en conjuntos de datos peque√±os:

- **Linear SVM (SVM lineal)**: clasificador lineal adecuado para espacios de
  alta dimensi√≥n.
- **Random Forest**: modelo basado en ensambles de √°rboles de decisi√≥n.
- **KNN (K-Nearest Neighbors)**: clasificador basado en vecinos m√°s cercanos.

El modelo SVM lineal present√≥ el mejor desempe√±o promedio en t√©rminos de
F1-score macro durante la validaci√≥n cruzada, por lo que fue seleccionado
como modelo final.

## üìä Resultado general

Los modelos fueron evaluados mediante validaci√≥n cruzada sobre el conjunto
de entrenamiento. Posteriormente, el modelo final se aplic√≥ a un conjunto de
prueba independiente para generar las predicciones.

A partir de la revisi√≥n manual de los videos de prueba se observ√≥ que muchos
errores est√°n asociados a movimientos adicionales durante la caminata
(sacar el tel√©fono, consultar el reloj, manipular objetos), as√≠ como a
inestabilidad en la detecci√≥n de la pose, principalmente en brazos, manos y
hombros. Estas condiciones afectan directamente los descriptores
calculados y explican parte de las confusiones observadas.

## üìÇ Organizaci√≥n del repositorio

Este repositorio incluye los siguientes archivos principales:

- `Sensado_an√°lisis_video.ipynb`  
  Notebook principal con todo el flujo de an√°lisis, entrenamiento y
  evaluaci√≥n.

- `batch_extract_pose.py`  
  Script utilizado para la extracci√≥n de landmarks corporales a partir de
  los videos y generaci√≥n de los archivos CSV de pose.

- `labels_example.csv`  
  Archivo de ejemplo con el formato de etiquetas utilizado por el notebook.
  Contiene √∫nicamente identificadores num√©ricos y se incluye como plantilla.

> Para ejecutar el notebook, renombra `labels_example.csv` a `labels.csv`.

El archivo real de etiquetas utilizado en el experimento no se incluye en
este repositorio.

## üìå Nota sobre el modelo de MediaPipe

El archivo del modelo de MediaPipe Pose (`pose_landmarker.task`) no se
incluye en el repositorio debido a restricciones de tama√±o.

Para poder ejecutar el script de extracci√≥n de pose, es necesario descargar
el modelo oficial de MediaPipe Pose y colocar el archivo
`pose_landmarker.task` en la misma carpeta que el script
`batch_extract_pose.py`.

## üìÅ Requisitos

Para ejecutar el notebook correctamente es necesario contar con:

- Python 3.x
- Librer√≠as principales:
  - `mediapipe`
  - `scikit-learn`
  - `numpy`
  - `pandas`
  - `matplotlib`
  - `opencv-python`

Si se desea reproducir el entorno completo utilizado en la pr√°ctica, se
incluye el archivo `environment.yml` para crear el entorno con conda.

